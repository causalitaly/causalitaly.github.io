<!doctype html><html lang=en dir=ltr>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta name=description content="weight: 1 bookFlatSection: true title: &ldquo;Programme&rdquo; #  Invited Speakers #  Sara Magliacane. Causality-inspired ML: what can causality do for ML? The domain adaptation case #  Abstract:
Applying machine learning to real-world cases often requires methods that are trustworthy and robust w.r.t. heterogeneity, missing not at random or corrupt data, selection bias, non i.i.d. data etc. and that can generalize across different domains. Moreover, many tasks are inherently trying to answer causal questions and gather actionable insights, a task for which correlations are usually not enough.">
<meta name=theme-color content="#FFFFFF"><meta property="og:title" content>
<meta property="og:description" content="weight: 1 bookFlatSection: true title: &ldquo;Programme&rdquo; #  Invited Speakers #  Sara Magliacane. Causality-inspired ML: what can causality do for ML? The domain adaptation case #  Abstract:
Applying machine learning to real-world cases often requires methods that are trustworthy and robust w.r.t. heterogeneity, missing not at random or corrupt data, selection bias, non i.i.d. data etc. and that can generalize across different domains. Moreover, many tasks are inherently trying to answer causal questions and gather actionable insights, a task for which correlations are usually not enough.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://causalitaly.github.io/docs/last/programme/"><meta property="article:section" content="docs">
<title>Programme | Causal-Italy</title>
<link rel=manifest href=/manifest.json>
<link rel=icon href=/favicon.png type=image/x-icon>
<link rel=stylesheet href=/book.min.57f7f660871517a5bfcfb5e2de853d806f7e34d94ebd5f3f3bad62e9ddbae209.css integrity="sha256-V/f2YIcVF6W/z7Xi3oU9gG9+NNlOvV8/O61i6d264gk=" crossorigin=anonymous>
</head>
<body dir=ltr>
<input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control>
<main class="container flex">
<aside class=book-menu>
<div class=book-menu-content>
<nav>
<h2 class=book-brand>
<a href=/><span>Causal-Italy</span>
</a>
</h2>
<ul>
<li class=book-section-flat>
<a href=https://causalitaly.github.io/docs/last/>Causal-ITALY2021</a>
<ul>
<li>
<a href=https://causalitaly.github.io/docs/last/cfp/>CFP</a>
</li>
<li>
<a href=https://causalitaly.github.io/docs/last/pc/>Organisation</a>
</li>
<li>
<a href=https://causalitaly.github.io/docs/last/programme/ class=active>Programme</a>
</li>
</ul>
</li>
</ul>
</nav>
<script>(function(){var a=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(b){localStorage.setItem("menu.scrollTop",a.scrollTop)}),a.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>
</div>
</aside>
<div class=book-page>
<header class=book-header>
<div class="flex align-center justify-between">
<label for=menu-control>
<img src=/svg/menu.svg class=book-icon alt=Menu>
</label>
<strong>Programme</strong>
<label for=toc-control>
</label>
</div>
</header>
<article class=markdown><h2 id=title-programme>
weight: 1
bookFlatSection: true
title: &ldquo;Programme&rdquo;
<a class=anchor href=#title-programme>#</a>
</h2>
<h1 id=invited-speakers>
Invited Speakers
<a class=anchor href=#invited-speakers>#</a>
</h1>
<h2 id=sara-magliacane-causality-inspired-ml-what-can-causality-do-for-ml-the-domain-adaptation-case>
Sara Magliacane. Causality-inspired ML: what can causality do for ML? The domain adaptation case
<a class=anchor href=#sara-magliacane-causality-inspired-ml-what-can-causality-do-for-ml-the-domain-adaptation-case>#</a>
</h2>
<p><em>Abstract:</em></p>
<p>Applying machine learning to real-world cases often requires methods that are trustworthy and robust w.r.t. heterogeneity, missing not at random or corrupt data, selection bias, non i.i.d. data etc. and that can generalize across different domains. Moreover, many tasks are inherently trying to answer causal questions and gather actionable insights, a task for which correlations are usually not enough. Several of these issues are addressed in the rich causal inference literature. On the other hand, often classical causal inference methods require either a complete knowledge of a causal graph or enough experimental data (interventions) to estimate it accurately.</p>
<p>Recently, a new line of research has focused on causality-inspired machine learning, i.e. on the application ideas from causal inference to machine learning methods without necessarily knowing or even trying to estimate the complete causal graph. In this talk, I will present an example of this line of research in the unsupervised domain adaptation case, in which we have labelled data in a set of source domains and unlabelled data in a target domain (&ldquo;zero-shot&rdquo;), for which we want to predict the labels. In particular, given certain assumptions, our approach is able to select a set of provably &ldquo;stable&rdquo; features (a separating set), for which the generalization error can be bound, even in case of arbitrarily large distribution shifts. As opposed to other works, it also exploits the information in the unlabelled target data, allowing for some unseen shifts w.r.t. to the source domains. While using ideas from causal inference, our method never aims at reconstructing the causal graph or even the Markov equivalence class, showing that causal inference ideas can help machine learning even in this more relaxed setting.</p>
<p><em>Links:</em>
<a href=https://arxiv.org/abs/1611.10351>https://arxiv.org/abs/1611.10351</a>
<a href=https://arxiv.org/abs/1707.06422>https://arxiv.org/abs/1707.06422</a></p>
<p><em>Bio:</em>
Sara Magliacane is an assistant professor in the Informatics Institute at the University of Amsterdam and a Research Scientist at the MIT-IBM Watson AI Lab. She received her PhD at the VU Amsterdam on logics for causal inference under uncertainty in 2017, focusing on learning causal relations jointly from different experimental settings, especially in the case of latent confounders and small samples. After a year in IBM Research NY as a postdoc, she joined the MIT-IBM Watson AI Lab in 2019 as a Research Scientist, where she has been working on methods to design experiments that would allow one to learn causal relations in a sample-efficient and intervention-efficient way. Her current focus is on causality-inspired machine learning, i.e. applications of causal inference to machine learning and especially transfer learning, and formally safe reinforcement learning.</p>
<h2 id=lorenzo-magnani>
Lorenzo Magnani
<a class=anchor href=#lorenzo-magnani>#</a>
</h2>
</article>
<footer class=book-footer>
<div class="flex flex-wrap justify-between">
</div>
<script>(function(){function a(c){const a=window.getSelection(),b=document.createRange();b.selectNodeContents(c),a.removeAllRanges(),a.addRange(b)}document.querySelectorAll("pre code").forEach(b=>{b.addEventListener("click",function(c){a(b.parentElement),navigator.clipboard&&navigator.clipboard.writeText(b.parentElement.textContent)})})})()</script>
</footer>
<label for=menu-control class="hidden book-menu-overlay"></label>
</div>
</main>
</body>
</html>